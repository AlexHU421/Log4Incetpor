package entity.RegexLib;

import java.util.regex.Matcher;
import java.util.regex.Pattern;

public class FilterErrorRegexLib {
	static Pattern p;
	static Matcher matcher;
	public static void main(String[] args) {
		String error1 = 
				"2017-07-27 09:00:13,338 INFO  ql.Driver: (PerfLogger.java:PerfLogEnd(133)) [HiveServer2-Handler-Pool: Thread-8952418(SessionHandle=1fa51a07-e05f-40cf-9c40-1498a939e722)] - </PERFLOG method=compile start=1501117213332 end=1501117213338 duration=6>!The Error :!ANONYMOUS BLOCK (LINE 1, COLUMN 6, TEXT ”Transfer_ItomEbank_PerHour('2017-07-27','08:%')”): BUG! Transfer_ItomEbank_PerHour is not any of UDF/PL function/collection name.!NewLine!org.apache.hadoop.hive.ql.parse.SemanticException: !NewLine!ANONYMOUS BLOCK (LINE 1, COLUMN 6, TEXT “Transfer_ItomEbank_PerHour('2017-07-27','08:%')”): BUG! Transfer_ItomEbank_PerHour is not any of UDF/PL function/collection name.!NewLine!	at org.apache.hadoop.hive.ql.pl.parse.PLBlkParser.parsePLBlk(PLBlkParser.java:198)!NewLine!	at org.apache.hadoop.hive.ql.pl.parse.PLSemanticAnalyzer.analyzeAnonExec(PLSemanticAnalyzer.java:1104)!NewLine!	at org.apache.hadoop.hive.ql.pl.parse.PLSemanticAnalyzer.analyzeInternal(PLSemanticAnalyzer.java:73)!NewLine!	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:494)!NewLine!	at io.transwarp.inceptor.InceptorDriver.compile(InceptorDriver.scala:339)!NewLine!	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:414)!NewLine!	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1451)!NewLine!	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1506)!NewLine!	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1386)!NewLine!	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1356)!NewLine!	at io.transwarp.inceptor.server.InceptorSQLOperation.runInternal(InceptorSQLOperation.scala:66)!NewLine!	at org.apache.hive.service.cli.operation.Operation.run(Operation.java:279)!NewLine!	at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementInternal(HiveSessionImpl.java:427)!NewLine!	at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementWithParamsAndPropertiesAsync(HiveSessionImpl.java:394)!NewLine!	at org.apache.hive.service.cli.CLIService.executeStatementWithParamsAndPropertiesAsync(CLIService.java:320)!NewLine!	at io.transwarp.inceptor.server.InceptorCLIService.executeStatementWithParamsAndPropertiesAsync(InceptorCLIService.scala:130)!NewLine!	at org.apache.hive.service.cli.thrift.ThriftCLIService.ExecuteStatement(ThriftCLIService.java:546)!NewLine!	at org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1737)!NewLine!	at org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1722)!NewLine!	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)!NewLine!	at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)!NewLine!	at org.apache.hive.service.auth.TSetIpAddressProcessor.process(TSetIpAddressProcessor.java:56)!NewLine!	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:285)!NewLine!	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)!NewLine!	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)!NewLine!	at java.lang.Thread.run(Thread.java:745)!NewLine!Caused by: org.apache.hadoop.hive.ql.parse.SemanticException: BUG! Transfer_ItomEbank_PerHour is not any of UDF/PL function/collection name.!NewLine!	at org.apache.hadoop.hive.ql.pl.parse.PLBlkParseProcFactory$FunctionProc.processInternal(PLBlkParseProcFactory.java:525)!NewLine!	at org.apache.hadoop.hive.ql.pl.parse.PLBlkParseProcFactory$PLProc.process(PLBlkParseProcFactory.java:56)!NewLine!	at org.apache.hadoop.hive.ql.lib.DefaultRuleDispatcher.dispatch(DefaultRuleDispatcher.java:90)!NewLine!	at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.dispatchAndReturn(DefaultGraphWalker.java:98)!NewLine!	at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.dispatch(DefaultGraphWalker.java:82)!NewLine!	at org.apache.hadoop.hive.ql.pl.parse.PLBlkParseGraphWalker.walk(PLBlkParseGraphWalker.java:53)!NewLine!	at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.startWalking(DefaultGraphWalker.java:113)!NewLine!	at org.apache.hadoop.hive.ql.pl.parse.PLBlkParser.parsePLBlk(PLBlkParser.java:188)!NewLine!	... 25 more!NewLine!";
		String error2 =
				"2017-07-27 09:00:13,355 INFO  ql.Driver: (Driver.java:stopHeartbeatThread(1164)) [HiveServer2-Handler-Pool: Thread-8952418()] - stop the heartbeat thread for session: 1fa51a07-e05f-40cf-9c40-1498a939e722!The Error :!org.apache.hive.service.cli.HiveSQLException: COMPILE FAILED: Semantic error: [Error 11261] !NewLine!ANONYMOUS BLOCK (LINE 1, COLUMN 6, TEXT “Transfer_ItomEbank_PerHour('2017-07-27','08:%')”): BUG! Transfer_ItomEbank_PerHour is not any of UDF/PL function/collection name.!NewLine!	at io.transwarp.inceptor.server.InceptorSQLOperation.runInternal(InceptorSQLOperation.scala:84)!NewLine!	at org.apache.hive.service.cli.operation.Operation.run(Operation.java:279)!NewLine!	at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementInternal(HiveSessionImpl.java:427)!NewLine!	at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementWithParamsAndPropertiesAsync(HiveSessionImpl.java:394)!NewLine!	at org.apache.hive.service.cli.CLIService.executeStatementWithParamsAndPropertiesAsync(CLIService.java:320)!NewLine!	at io.transwarp.inceptor.server.InceptorCLIService.executeStatementWithParamsAndPropertiesAsync(InceptorCLIService.scala:130)!NewLine!	at org.apache.hive.service.cli.thrift.ThriftCLIService.ExecuteStatement(ThriftCLIService.java:546)!NewLine!	at org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1737)!NewLine!	at org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1722)!NewLine!	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)!NewLine!	at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)!NewLine!	at org.apache.hive.service.auth.TSetIpAddressProcessor.process(TSetIpAddressProcessor.java:56)!NewLine!	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:285)!NewLine!	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)!NewLine!	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)!NewLine!	at java.lang.Thread.run(Thread.java:745)!NewLine!";
		String error3 = 
				"2017-07-27 09:00:13,355 INFO  ql.Driver: (Driver.java:stopHeartbeatThread(1164)) [HiveServer2-Handler-Pool: Thread-8952418()] - stop the heartbeat thread for session: 1fa51a07-e05f-40cf-9c40-1498a939e722!The Error :!org.apache.hive.service.cli.HiveSQLException: COMPILE FAILED: Semantic error: [Error 11261] !NewLine!ANONYMOUS BLOCK (LINE 1, COLUMN 6, TEXT “Transfer_ItomEbank_PerHour('2017-07-27','08:%')”): BUG! Transfer_ItomEbank_PerHour is not any of UDF/PL function/collection name.!NewLine!	at io.transwarp.inceptor.server.InceptorSQLOperation.runInternal(InceptorSQLOperation.scala:84)!NewLine!	at org.apache.hive.service.cli.operation.Operation.run(Operation.java:279)!NewLine!	at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementInternal(HiveSessionImpl.java:427)!NewLine!	at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementWithParamsAndPropertiesAsync(HiveSessionImpl.java:394)!NewLine!	at org.apache.hive.service.cli.CLIService.executeStatementWithParamsAndPropertiesAsync(CLIService.java:320)!NewLine!	at io.transwarp.inceptor.server.InceptorCLIService.executeStatementWithParamsAndPropertiesAsync(InceptorCLIService.scala:130)!NewLine!	at org.apache.hive.service.cli.thrift.ThriftCLIService.ExecuteStatement(ThriftCLIService.java:546)!NewLine!	at org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1737)!NewLine!	at org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1722)!NewLine!	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)!NewLine!	at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)!NewLine!	at org.apache.hive.service.auth.TSetIpAddressProcessor.process(TSetIpAddressProcessor.java:56)!NewLine!	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:285)!NewLine!	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)!NewLine!	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)!NewLine!	at java.lang.Thread.run(Thread.java:745)!NewLine!";
		String error4 =
				"2017-07-27 09:00:17,187 INFO  ql.Driver: (Driver.java:stopHeartbeatThread(1164)) [HiveServer2-Handler-Pool: Thread-8952418()] - stop the heartbeat thread for session: 6e6d8262-47ae-4629-b8c7-1dc19413f881!The Error :!org.apache.hive.service.cli.HiveSQLException: COMPILE FAILED: Semantic error: [Error 11261] !NewLine!ANONYMOUS BLOCK (LINE 1, COLUMN 6, TEXT “Transfer_ItomEbank_Perplat_PerHour('2017-07-27','08:%')”): BUG! Transfer_ItomEbank_Perplat_PerHour is not any of UDF/PL function/collection name.!NewLine!	at io.transwarp.inceptor.server.InceptorSQLOperation.runInternal(InceptorSQLOperation.scala:84)!NewLine!	at org.apache.hive.service.cli.operation.Operation.run(Operation.java:279)!NewLine!	at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementInternal(HiveSessionImpl.java:427)!NewLine!	at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementWithParamsAndPropertiesAsync(HiveSessionImpl.java:394)!NewLine!	at org.apache.hive.service.cli.CLIService.executeStatementWithParamsAndPropertiesAsync(CLIService.java:320)!NewLine!	at io.transwarp.inceptor.server.InceptorCLIService.executeStatementWithParamsAndPropertiesAsync(InceptorCLIService.scala:130)!NewLine!	at org.apache.hive.service.cli.thrift.ThriftCLIService.ExecuteStatement(ThriftCLIService.java:546)!NewLine!	at org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1737)!NewLine!	at org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1722)!NewLine!	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)!NewLine!	at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)!NewLine!	at org.apache.hive.service.auth.TSetIpAddressProcessor.process(TSetIpAddressProcessor.java:56)!NewLine!	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:285)!NewLine!	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)!NewLine!	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)!NewLine!	at java.lang.Thread.run(Thread.java:745)!NewLine!";
		String error5 = 
				"2017-07-27 09:05:13,413 INFO  ql.Driver: (PerfLogger.java:PerfLogEnd(133)) [HiveServer2-Handler-Pool: Thread-8952891(SessionHandle=cb324523-de5f-437f-a8d8-6cb4571b050a)] - </PERFLOG method=compile start=1501117513407 end=1501117513413 duration=6>!The Error :!ANONYMOUS BLOCK (LINE 1, COLUMN 6, TEXT “MenuCountHour('2017-07-27 08:00','2017-07-27','08:%','visitor')”): BUG! MenuCountHour is not any of UDF/PL function/collection name.!NewLine!org.apache.hadoop.hive.ql.parse.SemanticException: !NewLine!ANONYMOUS BLOCK (LINE 1, COLUMN 6, TEXT “MenuCountHour('2017-07-27 08:00','2017-07-27','08:%','visitor')”): BUG! MenuCountHour is not any of UDF/PL function/collection name.!NewLine!	at org.apache.hadoop.hive.ql.pl.parse.PLBlkParser.parsePLBlk(PLBlkParser.java:198)!NewLine!	at org.apache.hadoop.hive.ql.pl.parse.PLSemanticAnalyzer.analyzeAnonExec(PLSemanticAnalyzer.java:1104)!NewLine!	at org.apache.hadoop.hive.ql.pl.parse.PLSemanticAnalyzer.analyzeInternal(PLSemanticAnalyzer.java:73)!NewLine!	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:494)!NewLine!	at io.transwarp.inceptor.InceptorDriver.compile(InceptorDriver.scala:339)!NewLine!	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:414)!NewLine!	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1451)!NewLine!	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1506)!NewLine!	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1386)!NewLine!	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1356)!NewLine!	at io.transwarp.inceptor.server.InceptorSQLOperation.runInternal(InceptorSQLOperation.scala:66)!NewLine!	at org.apache.hive.service.cli.operation.Operation.run(Operation.java:279)!NewLine!	at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementInternal(HiveSessionImpl.java:427)!NewLine!	at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementWithParamsAndPropertiesAsync(HiveSessionImpl.java:394)!NewLine!	at org.apache.hive.service.cli.CLIService.executeStatementWithParamsAndPropertiesAsync(CLIService.java:320)!NewLine!	at io.transwarp.inceptor.server.InceptorCLIService.executeStatementWithParamsAndPropertiesAsync(InceptorCLIService.scala:130)!NewLine!	at org.apache.hive.service.cli.thrift.ThriftCLIService.ExecuteStatement(ThriftCLIService.java:546)!NewLine!	at org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1737)!NewLine!	at org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1722)!NewLine!	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)!NewLine!	at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)!NewLine!	at org.apache.hive.service.auth.TSetIpAddressProcessor.process(TSetIpAddressProcessor.java:56)!NewLine!	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:285)!NewLine!	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)!NewLine!	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)!NewLine!	at java.lang.Thread.run(Thread.java:745)!NewLine!Caused by: org.apache.hadoop.hive.ql.parse.SemanticException: BUG! MenuCountHour is not any of UDF/PL function/collection name.!NewLine!	at org.apache.hadoop.hive.ql.pl.parse.PLBlkParseProcFactory$FunctionProc.processInternal(PLBlkParseProcFactory.java:525)!NewLine!	at org.apache.hadoop.hive.ql.pl.parse.PLBlkParseProcFactory$PLProc.process(PLBlkParseProcFactory.java:56)!NewLine!	at org.apache.hadoop.hive.ql.lib.DefaultRuleDispatcher.dispatch(DefaultRuleDispatcher.java:90)!NewLine!	at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.dispatchAndReturn(DefaultGraphWalker.java:98)!NewLine!	at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.dispatch(DefaultGraphWalker.java:82)!NewLine!	at org.apache.hadoop.hive.ql.pl.parse.PLBlkParseGraphWalker.walk(PLBlkParseGraphWalker.java:53)!NewLine!	at org.apache.hadoop.hive.ql.lib.DefaultGraphWalker.startWalking(DefaultGraphWalker.java:113)!NewLine!	at org.apache.hadoop.hive.ql.pl.parse.PLBlkParser.parsePLBlk(PLBlkParser.java:188)!NewLine!	... 25 more!NewLine!";
		String error6 =
				"2017-07-27 09:05:13,430 INFO  ql.Driver: (Driver.java:stopHeartbeatThread(1164)) [HiveServer2-Handler-Pool: Thread-8952891()] - stop the heartbeat thread for session: cb324523-de5f-437f-a8d8-6cb4571b050a!The Error :!org.apache.hive.service.cli.HiveSQLException: COMPILE FAILED: Semantic error: [Error 11261] !NewLine!ANONYMOUS BLOCK (LINE 1, COLUMN 6, TEXT “MenuCountHour('2017-07-27 08:00','2017-07-27','08:%','visitor')”): BUG! MenuCountHour is not any of UDF/PL function/collection name.!NewLine!	at io.transwarp.inceptor.server.InceptorSQLOperation.runInternal(InceptorSQLOperation.scala:84)!NewLine!	at org.apache.hive.service.cli.operation.Operation.run(Operation.java:279)!NewLine!	at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementInternal(HiveSessionImpl.java:427)!NewLine!	at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementWithParamsAndPropertiesAsync(HiveSessionImpl.java:394)!NewLine!	at org.apache.hive.service.cli.CLIService.executeStatementWithParamsAndPropertiesAsync(CLIService.java:320)!NewLine!	at io.transwarp.inceptor.server.InceptorCLIService.executeStatementWithParamsAndPropertiesAsync(InceptorCLIService.scala:130)!NewLine!	at org.apache.hive.service.cli.thrift.ThriftCLIService.ExecuteStatement(ThriftCLIService.java:546)!NewLine!	at org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1737)!NewLine!	at org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1722)!NewLine!	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)!NewLine!	at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)!NewLine!	at org.apache.hive.service.auth.TSetIpAddressProcessor.process(TSetIpAddressProcessor.java:56)!NewLine!	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:285)!NewLine!	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)!NewLine!	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)!NewLine!	at java.lang.Thread.run(Thread.java:745)!NewLine!";
		String error7 = 
				"2017-07-27 09:25:58,136 INFO  scheduler.StatsReportListener: (Logging.scala:logInfo(59)) [SparkListenerBus()] - task runtime:(count: 8, mean: 59.500000, stdev: 18.200275, max: 92.000000, min: 39.000000)!The Error :!org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 3081677.0 failed 4 times, most recent failure: Lost task 1.3 in stage 3081677.0 (TID 3190800, dbclusternode013): org.apache.hadoop.hive.ql.metadata.HiveException: Index: 3, Size: 3!NewLine!        org.apache.hadoop.hive.ql.exec.FileSinkOperator.processOp(FileSinkOperator.java:1143)!NewLine!        io.transwarp.inceptor.execution.FileSinkOperator$$anonfun$processPartition$3.apply(FileSinkOperator.scala:118)!NewLine!        io.transwarp.inceptor.execution.FileSinkOperator$$anonfun$processPartition$3.apply(FileSinkOperator.scala:115)!NewLine!        scala.collection.Iterator$class.foreach(Iterator.scala:727)!NewLine!        org.apache.spark.util.CompletionIterator.foreach(CompletionIterator.scala:25)!NewLine!        io.transwarp.inceptor.execution.FileSinkOperator.processPartition(FileSinkOperator.scala:115)!NewLine!        io.transwarp.inceptor.execution.FileSinkOperator$.io$transwarp$inceptor$execution$FileSinkOperator$$writeFiles$1(FileSinkOperator.scala:289)!NewLine!        io.transwarp.inceptor.execution.FileSinkOperator$$anonfun$executeProcessFileSinkPartition$1.apply(FileSinkOperator.scala:293)!NewLine!        io.transwarp.inceptor.execution.FileSinkOperator$$anonfun$executeProcessFileSinkPartition$1.apply(FileSinkOperator.scala:293)!NewLine!        org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:73)!NewLine!        org.apache.spark.scheduler.Task.run(Task.scala:62)!NewLine!        org.apache.spark.executor.Executor$TaskRunner$$anonfun$run$1.apply$mcV$sp(Executor.scala:265)!NewLine!        org.apache.spark.deploy.SparkHadoopUtil.runAsUser(SparkHadoopUtil.scala:58)!NewLine!        org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:224)!NewLine!        java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)!NewLine!        java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)!NewLine!        java.lang.Thread.run(Thread.java:745)!NewLine!Driver stacktrace:!NewLine!	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1595)!NewLine!	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1584)!NewLine!	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1583)!NewLine!	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)!NewLine!	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)!NewLine!	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1583)!NewLine!	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:992)!NewLine!	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:992)!NewLine!	at scala.Option.foreach(Option.scala:236)!NewLine!	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:992)!NewLine!	at org.apache.spark.scheduler.DAGSchedulerEventProcessActor$$anonfun$receive$2.applyOrElse(DAGScheduler.scala:1836)!NewLine!	at scala.runtime.AbstractPartialFunction$mcVL$sp.apply$mcVL$sp(AbstractPartialFunction.scala:33)!NewLine!	at scala.runtime.AbstractPartialFunction$mcVL$sp.apply(AbstractPartialFunction.scala:33)!NewLine!	at scala.runtime.AbstractPartialFunction$mcVL$sp.apply(AbstractPartialFunction.scala:25)!NewLine!	at org.apache.spark.scheduler.DAGSchedulerEventProcessActor$$anonfun$receiveTiming$1.applyOrElse(DAGScheduler.scala:1792)!NewLine!	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:498)!NewLine!	at akka.actor.ActorCell.invoke(ActorCell.scala:456)!NewLine!	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:237)!NewLine!	at akka.dispatch.Mailbox.run(Mailbox.scala:219)!NewLine!	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:386)!NewLine!	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)!NewLine!	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)!NewLine!	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)!NewLine!	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)!NewLine!";
		String error8 = 
				"2017-07-27 09:26:08,433 INFO  scheduler.StatsReportListener: (Logging.scala:logInfo(59)) [SparkListenerBus()] - executor (non-fetch) time pct: (count: 8, mean: 92.188307, stdev: 5.135630, max: 98.437500, min: 82.474227)!The Error :!org.apache.hive.service.cli.HiveSQLException: EXECUTION FAILED: Task MAPRED-SPARK error SparkException: [Error 1] Job aborted due to stage failure: Task 1 in stage 3081684.0 failed 4 times, most recent failure: Lost task 1.3 in stage 3081684.0 (TID 3190815, dbclusternode013): org.apache.hadoop.hive.ql.metadata.HiveException: Index: 3, Size: 3!NewLine!	at io.transwarp.inceptor.server.InceptorSQLOperation.runInternal(InceptorSQLOperation.scala:84)!NewLine!	at org.apache.hive.service.cli.operation.Operation.run(Operation.java:279)!NewLine!	at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementInternal(HiveSessionImpl.java:427)!NewLine!	at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementWithParamsAndPropertiesAsync(HiveSessionImpl.java:394)!NewLine!	at org.apache.hive.service.cli.CLIService.executeStatementWithParamsAndPropertiesAsync(CLIService.java:320)!NewLine!	at io.transwarp.inceptor.server.InceptorCLIService.executeStatementWithParamsAndPropertiesAsync(InceptorCLIService.scala:130)!NewLine!	at org.apache.hive.service.cli.thrift.ThriftCLIService.ExecuteStatement(ThriftCLIService.java:546)!NewLine!	at org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1737)!NewLine!	at org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1722)!NewLine!	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)!NewLine!	at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)!NewLine!	at org.apache.hive.service.auth.TSetIpAddressProcessor.process(TSetIpAddressProcessor.java:56)!NewLine!	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:285)!NewLine!	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)!NewLine!	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)!NewLine!	at java.lang.Thread.run(Thread.java:745)!NewLine!";
		String error9 = 
				"2017-07-27 09:26:17,612 WARN  ipc.Client: (Client.java:run(683)) [Thread-100()] - Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): token (owner=hive/dbclusternode014@TDH, renewer=YARN, realUser=, issueDate=1493980386616, maxDate=1494585186616, sequenceNumber=7, masterKeyId=67) can't be found in cache!The Error :!org.apache.hive.service.cli.HiveSQLException: COMPILE FAILED: Semantic error: [Error 10044] Line 1:12 Cannot insert into target table because column number/types are different 'bpp_memect_zb_holder': Cannot convert column 0 from:!NewLine!	at io.transwarp.inceptor.server.InceptorSQLOperation.runInternal(InceptorSQLOperation.scala:84)!NewLine!	at org.apache.hive.service.cli.operation.Operation.run(Operation.java:279)!NewLine!	at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementInternal(HiveSessionImpl.java:427)!NewLine!	at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementWithParamsAndPropertiesAsync(HiveSessionImpl.java:394)!NewLine!	at org.apache.hive.service.cli.CLIService.executeStatementWithParamsAndPropertiesAsync(CLIService.java:320)!NewLine!	at io.transwarp.inceptor.server.InceptorCLIService.executeStatementWithParamsAndPropertiesAsync(InceptorCLIService.scala:130)!NewLine!	at org.apache.hive.service.cli.thrift.ThriftCLIService.ExecuteStatement(ThriftCLIService.java:546)!NewLine!	at org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1737)!NewLine!	at org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1722)!NewLine!	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)!NewLine!	at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)!NewLine!	at org.apache.hive.service.auth.TSetIpAddressProcessor.process(TSetIpAddressProcessor.java:56)!NewLine!	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:285)!NewLine!	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)!NewLine!	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)!NewLine!	at java.lang.Thread.run(Thread.java:745)!NewLine!";
		String error10 = 
				"2017-07-27 09:27:32,882 INFO  scheduler.StatsReportListener: (Logging.scala:logInfo(59)) [SparkListenerBus()] - Finished stage: org.apache.spark.scheduler.StageInfo@655dbf3a!The Error :!org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 3081734.0 failed 4 times, most recent failure: Lost task 1.3 in stage 3081734.0 (TID 3190884, dbclusternode016): org.apache.hadoop.hive.ql.metadata.HiveException: Index: 3, Size: 3!NewLine!        org.apache.hadoop.hive.ql.exec.FileSinkOperator.processOp(FileSinkOperator.java:1143)!NewLine!        io.transwarp.inceptor.execution.FileSinkOperator$$anonfun$processPartition$3.apply(FileSinkOperator.scala:118)!NewLine!        io.transwarp.inceptor.execution.FileSinkOperator$$anonfun$processPartition$3.apply(FileSinkOperator.scala:115)!NewLine!        scala.collection.Iterator$class.foreach(Iterator.scala:727)!NewLine!        org.apache.spark.util.CompletionIterator.foreach(CompletionIterator.scala:25)!NewLine!        io.transwarp.inceptor.execution.FileSinkOperator.processPartition(FileSinkOperator.scala:115)!NewLine!        io.transwarp.inceptor.execution.FileSinkOperator$.io$transwarp$inceptor$execution$FileSinkOperator$$writeFiles$1(FileSinkOperator.scala:289)!NewLine!        io.transwarp.inceptor.execution.FileSinkOperator$$anonfun$executeProcessFileSinkPartition$1.apply(FileSinkOperator.scala:293)!NewLine!        io.transwarp.inceptor.execution.FileSinkOperator$$anonfun$executeProcessFileSinkPartition$1.apply(FileSinkOperator.scala:293)!NewLine!        org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:73)!NewLine!        org.apache.spark.scheduler.Task.run(Task.scala:62)!NewLine!        org.apache.spark.executor.Executor$TaskRunner$$anonfun$run$1.apply$mcV$sp(Executor.scala:265)!NewLine!        org.apache.spark.deploy.SparkHadoopUtil.runAsUser(SparkHadoopUtil.scala:58)!NewLine!        org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:224)!NewLine!        java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)!NewLine!        java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)!NewLine!        java.lang.Thread.run(Thread.java:745)!NewLine!Driver stacktrace:!NewLine!	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1595)!NewLine!	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1584)!NewLine!	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1583)!NewLine!	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)!NewLine!	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)!NewLine!	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1583)!NewLine!	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:992)!NewLine!	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:992)!NewLine!	at scala.Option.foreach(Option.scala:236)!NewLine!	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:992)!NewLine!	at org.apache.spark.scheduler.DAGSchedulerEventProcessActor$$anonfun$receive$2.applyOrElse(DAGScheduler.scala:1836)!NewLine!	at scala.runtime.AbstractPartialFunction$mcVL$sp.apply$mcVL$sp(AbstractPartialFunction.scala:33)!NewLine!	at scala.runtime.AbstractPartialFunction$mcVL$sp.apply(AbstractPartialFunction.scala:33)!NewLine!	at scala.runtime.AbstractPartialFunction$mcVL$sp.apply(AbstractPartialFunction.scala:25)!NewLine!	at org.apache.spark.scheduler.DAGSchedulerEventProcessActor$$anonfun$receiveTiming$1.applyOrElse(DAGScheduler.scala:1792)!NewLine!	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:498)!NewLine!	at akka.actor.ActorCell.invoke(ActorCell.scala:456)!NewLine!	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:237)!NewLine!	at akka.dispatch.Mailbox.run(Mailbox.scala:219)!NewLine!	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:386)!NewLine!	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)!NewLine!	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)!NewLine!	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)!NewLine!	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)!NewLine!";
		String error11 = 
				"2017-07-27 09:27:32,883 INFO  scheduler.StatsReportListener: (Logging.scala:logInfo(59)) [SparkListenerBus()] - 	0.0 B	0.0 B	0.0 B	0.0 B	0.0 B	0.0 B	0.0 B	0.0 B	0.0 B!The Error :!org.apache.hive.service.cli.HiveSQLException: EXECUTION FAILED: Task MAPRED-SPARK error SparkException: [Error 1] Job aborted due to stage failure: Task 1 in stage 3081734.0 failed 4 times, most recent failure: Lost task 1.3 in stage 3081734.0 (TID 3190884, dbclusternode016): org.apache.hadoop.hive.ql.metadata.HiveException: Index: 3, Size: 3!NewLine!	at io.transwarp.inceptor.server.InceptorSQLOperation.runInternal(InceptorSQLOperation.scala:84)!NewLine!	at org.apache.hive.service.cli.operation.Operation.run(Operation.java:279)!NewLine!	at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementInternal(HiveSessionImpl.java:427)!NewLine!	at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementWithParamsAndPropertiesAsync(HiveSessionImpl.java:394)!NewLine!	at org.apache.hive.service.cli.CLIService.executeStatementWithParamsAndPropertiesAsync(CLIService.java:320)!NewLine!	at io.transwarp.inceptor.server.InceptorCLIService.executeStatementWithParamsAndPropertiesAsync(InceptorCLIService.scala:130)!NewLine!	at org.apache.hive.service.cli.thrift.ThriftCLIService.ExecuteStatement(ThriftCLIService.java:546)!NewLine!	at org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1737)!NewLine!	at org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1722)!NewLine!	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)!NewLine!	at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)!NewLine!	at org.apache.hive.service.auth.TSetIpAddressProcessor.process(TSetIpAddressProcessor.java:56)!NewLine!	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:285)!NewLine!	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)!NewLine!	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)!NewLine!	at java.lang.Thread.run(Thread.java:745)!NewLine!";
		String[] sz = new String[]{error1,error2,error3,error4,error5,error6,error7,error8,error9,error10,error11};
		int i = 0;
		for (String str:sz){
			i++;
			matcher = p.compile("Exception").matcher(str);
			if (matcher.find()){
				System.out.println(i);
			}
		}
	}
}
